# -*- mode: ruby -*-
# vi: set ft=ruby :

# Yakity
#
# Copyright (c) 2018 VMware, Inc. All Rights Reserved.
#
# This product is licensed to you under the Apache 2.0 license (the "License").
# You may not use this product except in compliance with the Apache 2.0 License.
#
# This product may include a number of subcomponents with separate copyright
# notices and license terms. Your use of these subcomponents is subject to the
# terms and conditions of the subcomponent's license, as noted in the LICENSE
# file.

# Define some default values.
CONFIG=ENV['CONFIG'] || 'config.yaml'
YAKITY_SH='../yakity.sh'
YAKITY_SERVICE='yakity.service'
NEW_CA_SH='../hack/new-ca.sh'
NEW_CERT_SH='../hack/new-cert.sh'
NEW_KUBECONFIG_SH='../hack/new-kubeconfig.sh'
VAGRANT_PROVIDER=ENV['VAGRANT_DEFAULT_PROVIDER'] || 'virtualbox'
VAGRANT_DOTFILE_PATH=ENV['VAGRANT_DOTFILE_PATH'] || '.'
TLS_CA_CRT="#{VAGRANT_DOTFILE_PATH}/ca.crt"
TLS_CA_KEY="#{VAGRANT_DOTFILE_PATH}/ca.key"
K8S_ADMIN_CRT="#{VAGRANT_DOTFILE_PATH}/k8s-admin.crt"
K8S_ADMIN_KEY="#{VAGRANT_DOTFILE_PATH}/k8s-admin.key"
KUBECONFIG="#{VAGRANT_DOTFILE_PATH}/machines/c01/#{VAGRANT_PROVIDER}/kubeconfig"
DNSCONFIG="#{VAGRANT_DOTFILE_PATH}/machines/c01/#{VAGRANT_PROVIDER}/dnsconfig"

# Load the config file if it exists.
require 'yaml'
$config = YAML.load_file(CONFIG)
if (!File.file?(CONFIG))
  puts "missing config file: #{CONFIG}"
  exit 1
end

require 'yaml'
$config = YAML.load_file(CONFIG)

$box = $config['box'] || abort('box required')
$cpu = $config['cpu'] || abort('cpu required')
$mem = $config['mem'] || abort('mem required')
$num_nodes = $config['nodes'] || abort('nodes required')
$num_controllers = $config['controllers'] || abort('controllers required')
$num_both = $config['both'] || abort('both required')
$num_workers = $num_nodes-$num_controllers

# Create the node definitions.
$nodes = []
for i in 1..$num_nodes do
  if (i <= $num_controllers)
    node_type = i <= ($num_controllers-$num_both) ? "controller" : "both"
    host_name = sprintf("c%02d", i)
  else
    node_type = "worker"
    host_name = sprintf("w%02d", i-$num_controllers)
  end
  $nodes << {
    :host => host_name,
    :type => node_type
  }
end

# The Photon box ships with a static machine-id, which means
# in a multi-machine deployment, all the boxes will have the
# same DHCP-provided IP address. This causes yakity to break
# since etcd is advertising IP addresses that must be unique.
#
# This script disables the host-only NIC, recreates the
# machine-id, and reenables the host-only NIC, thereby causing
# the machine to request a new, unique IP address from the DHCP
# server.
$init_photon_script = <<-EOF
ifconfig eth1 down
rm -f /etc/machine-id
dbus-uuidgen --ensure=/etc/machine-id
ifconfig eth1 up

rm -f /etc/modules-load.d/virtualbox.conf
tdnf install -y gawk \
                unzip \
                lsof \
                bindutils \
                iputils \
                tar
EOF

$init_guest_script = <<-EOF
mkdir -p /var/lib/yakity
chown vagrant /var/lib/yakity
EOF

# Ubuntu doesn't automatically source /etc/profile, so let's do that.
$init_ubuntu_script = <<-EOF
echo '. /etc/profile' >>/home/vagrant/.bashrc
EOF

# If there is more than one node an etcd discovery URL needs to be generated.
$etcd_disco = $num_nodes <= 1 ? 
  "" : `curl -sSL https://discovery.etcd.io/new?size=#{$num_controllers}`

# Generate a self-signed CA to use with the box(es).
if (not File.file?(TLS_CA_CRT) or not File.file?(TLS_CA_KEY))
  `TLS_CA_CRT=#{TLS_CA_CRT} \
  TLS_CA_KEY=#{TLS_CA_KEY} \
  #{NEW_CA_SH} >/dev/null 2>&1`
end
# Generate a cert for the k8s-admin user.
if (not File.file?(K8S_ADMIN_CRT) or not File.file?(K8S_ADMIN_KEY))
  `TLS_CA_CRT=#{TLS_CA_CRT} \
  TLS_CA_KEY=#{TLS_CA_KEY} \
  TLS_CRT_OUT=#{K8S_ADMIN_CRT} \
  TLS_KEY_OUT=#{K8S_ADMIN_KEY} \
  TLS_SAN=false \
  TLS_ORG_NAME="system:masters" \
  TLS_COMMON_NAME=admin \
  #{NEW_CERT_SH} >/dev/null 2>&1`
end

def copy_file_to_dir(node, src, dst="/var/lib/yakity")
  node.vm.provision "file", 
    source:       src, 
    destination:  "#{File.join(dst, File.basename(src))}"
end

Vagrant.configure("2") do |config|
  config.vm.box = $box
  config.vm.synced_folder ".", "/vagrant", disabled: true
  config.vm.network "private_network", type: "dhcp"

  # Set the provider preference order.
  config.vm.provider "virtualbox"
  config.vm.provider "vmware_fusion"

  config.vm.provider VAGRANT_PROVIDER do |p|
    case VAGRANT_PROVIDER
    when 'virtualbox'
      p.cpus =   $cpu
      p.memory = $mem
      p.customize ["modifyvm", :id, "--macaddress1", "auto"]
      p.customize ["modifyvm", :id, "--cpuexecutioncap", "50"]
    when 'vmware_desktop', 'vmware_fusion'
      p.vmx["numvcpus"] = $cpu
      p.vmx["memsize"]  = $mem
    end
  end

  # Generate the kubeconfig file.
  config.trigger.after :up do |trigger|
    trigger.info    = "Generating kubeconfig"
    trigger.only_on = /(?i)c01/
    trigger.run     = {
      :inline => <<-SHELL
        /bin/sh -c 'KUBECONFIG="#{KUBECONFIG}" \
        TLS_CA_CRT="#{TLS_CA_CRT}" \
        TLS_CA_KEY="#{TLS_CA_KEY}" \
        TLS_CRT="#{K8S_ADMIN_CRT}" \
        TLS_KEY="#{K8S_ADMIN_KEY}" \
        SERVER="https://127.0.0.1:$(vagrant port --guest 443 c01)" \
        USER="admin" \
        #{NEW_KUBECONFIG_SH} >/dev/null 2>&1'
      SHELL
    }
  end

  # Generate the DNS config file.
  config.trigger.after :up do |trigger|
    trigger.info    = "Generating DNS config"
    trigger.only_on = /(?i)c01/
    trigger.run     = {
      :inline => <<-SHELL
        /bin/sh -c 'echo "$(vagrant port --guest 53 c01)" > "#{DNSCONFIG}"'
      SHELL
    }
  end

  # Delete the kubeconfig file when the first node is destroyed.
  config.trigger.after :destroy do |trigger|
    trigger.info    = "Deleting kubeconfig"
    trigger.only_on = /(?i)c01/
    trigger.run     = {
      :inline => "/bin/rm -f '#{KUBECONFIG}'"
    }
  end

  # Delete the DNS config file when the first node is destroyed.
  config.trigger.after :destroy do |trigger|
    trigger.info    = "Deleting DNS config"
    trigger.only_on = /(?i)c01/
    trigger.run     = {
      :inline => "/bin/rm -f '#{DNSCONFIG}'"
    }
  end

  # Create the node(s)
  $nodes.each do |node_config|
    config.vm.define node_config[:host] do |node|

      # Assign the fully-qualified host name.
      node.vm.hostname = "#{node_config[:host]}.yakity"

      # Forward some ports for the control plane nodes.
      if (/(?i)^both|controller$/ =~ node_config[:type])
        node.vm.network "forwarded_port", 
          guest: 443, host: 6443, auto_correct: true
        node.vm.network "forwarded_port", 
          guest:  53, host: 6553, auto_correct: true
      end

      # Handle box-specific requirements.
      if (/(?i)photon/ =~ $box)
        node.vm.provision "init-guest", type: "shell" do |s|
          s.inline = <<-SHELL
            #{$init_guest_script}
            #{$init_photon_script}
          SHELL
        end
      elsif (/(?i)ubuntu/ =~ $box)
        node.vm.provision "init-guest", type: "shell" do |s|
          s.inline = <<-SHELL
            #{$init_guest_script}
            #{$init_ubuntu_script}
          SHELL
        end
      else
        node.vm.provision "init-guest", type: "shell" do |s|
          s.inline = <<-SHELL
            #{$init_guest_script}
          SHELL
        end
      end

      # Copy files to the VM.
      copy_file_to_dir node, YAKITY_SH
      copy_file_to_dir node, YAKITY_SERVICE
      copy_file_to_dir node, TLS_CA_CRT
      copy_file_to_dir node, TLS_CA_KEY

      node.vm.provision "init-yakity", type: "shell" do |s|
        s.inline = <<-SHELL
          mv /var/lib/yakity/ca.* /etc/ssl/
          chown root:root /etc/ssl/ca.crt /etc/ssl/ca.key
          chmod 0644 /etc/ssl/ca.crt
          chmod 0400 /etc/ssl/ca.key
          chmod 0755 /var/lib/yakity/yakity.sh

          nic=$(ip a | grep '^3:' | awk -F: '{print $2}' | tr -d '[:space:]')
          ip4=$(ip route get dev "${nic}" 1 | awk '{print $NF;exit}')

          cat <<EOF >/etc/default/yakity
IPV4_ADDRESS="${ip4}"
ETCD_DISCOVERY="#{$etcd_disco}"
NUM_NODES="#{$num_nodes}"
NUM_CONTROLLERS="#{$num_controllers}"
NODE_TYPE="#{node_config[:type]}"
INSTALL_CONFORMANCE_TESTS="false"
HOST_NAME_OVERRIDE="true"
FAIL_SWAP_ON="false"
EOF

          systemctl -l enable /var/lib/yakity/yakity.service
        SHELL
      end

      # Start yakity.
      node.vm.provision "start-yakity", type: "shell" do |s|
        s.inline = "systemctl -l --no-block start yakity"
      end
    end
  end
end
